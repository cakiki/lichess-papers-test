---
---

@article{adnan:2024:unleashing-artificial-cognition-integrating-multiple-ai-systems,
  title         = {Unleashing Artificial Cognition: Integrating Multiple {AI} Systems},
  author        = {Muntasir Adnan and Buddhi Gamage and Zhiwei Xu and Damith Herath and Carlos C. N. Kuhn},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2408.04910},
  doi           = {10.48550/ARXIV.2408.04910},
  url           = {https://doi.org/10.48550/arXiv.2408.04910},
  eprinttype    = {arXiv},
  eprint        = {2408.04910},
}

@inproceedings{ambrona:2022:practical-algorithm-chess-unwinnability,
  title         = {A Practical Algorithm for Chess Unwinnability},
  author        = {Miguel Ambrona},
  year          = {2022},
  booktitle     = {11th International Conference on Fun with Algorithms, {FUN} 2022, May 30 to June 3, 2022, Island of Favignana, Sicily, Italy},
  publisher     = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
  series        = {LIPIcs},
  volume        = {226},
  pages         = {2:1--2:20},
  doi           = {10.4230/LIPICS.FUN.2022.2},
  url           = {https://doi.org/10.4230/LIPIcs.FUN.2022.2},
  editor        = {Pierre Fraigniaud and Yushi Uno},
}

@misc{arora:2022:deep-learning-computer-chess,
  title         = {Deep learning for computer chess (part 1)},
  author        = {Manav Arora},
  year          = {2022},
  publisher     = {Nanyang Technological University},
  url           = {https://dr.ntu.edu.sg/handle/10356/157572?mode=full},
  note          = {Final Year Project (FYP)},
  abstract      = {This report encompasses the implementation of two state-of-the-art machine learning algorithms for evaluating chess positions. The first algorithm makes use of artificial neural networks and manual feature representation thus closely following the implementation and architecture of Matthew Lai's Giraffe.  Giraffe learns to play chess largely by self-play and derives its own rules based on the data [1]. Giraffe was implemented as a 7 class classification problem on a dataset of over 10,000 grandmaster level games. Four different implementations of Giraffe were explored covering two different architectures and the effects of regularization on the model performance. The second algorithm implemented goes through an unsupervised learning phase to perform feature extraction followed by a supervised learning phase thus replicating David Eli's DeepChess. DeepChess evaluates chess positions using a deep neural network without any a priori knowledge regarding the rules of chess. DeepChess is implemented as a siamese network of two disjoint deep belief networks connected to each other by fully connected layers [2]. This architecture was implemented as a binary classification problem on the same dataset as Giraffe and also on a larger dataset of LiChess games. Different implementations of DeepChess covering different training methodologies and parameter sets were executed.},
}

@article{baek:2024:wasm-r3-webassembly-benchmarks,
  title         = {Wasm-R3: Record-Reduce-Replay for Realistic and Standalone WebAssembly Benchmarks},
  author        = {Baek, Doehyun and Getz, Jakob and Sim, Yusung and Lehmann, Daniel and Titzer, Ben L. and Ryu, Sukyoung and Pradel, Michael},
  year          = {2024},
  month         = oct,
  journal       = {Proc. ACM Program. Lang.},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  volume        = {8},
  number        = {OOPSLA2},
  doi           = {10.1145/3689787},
  url           = {https://doi.org/10.1145/3689787},
  issue_date    = {October 2024},
  abstract      = {WebAssembly (Wasm for short) brings a new, powerful capability to the web as well as Edge, IoT, and embedded systems. Wasm is a portable, compact binary code format with high performance and robust sandboxing properties. As Wasm applications grow in size and importance, the complex performance characteristics of diverse Wasm engines demand robust, representative benchmarks for proper tuning. Stopgap benchmark suites, such as PolyBenchC and libsodium, continue to be used in the literature, though they are known to be unrepresentative. Porting of more complex suites remains difficult because Wasm lacks many system APIs and extracting real-world Wasm benchmarks from the web is difficult due to complex host interactions. To address this challenge, we introduce Wasm-R3, the first record and replay technique for Wasm. Wasm-R3 transparently injects instrumentation into Wasm modules to record an execution trace from inside the module, then reduces the execution trace via several optimizations, and finally produces a replay module that is executable standalone without any host environment-on any engine. The benchmarks created by our approach are (i) realistic, because the approach records real-world web applications, (ii) faithful to the original execution, because the replay benchmark includes the unmodified original code, only adding emulation of host interactions, and (iii) standalone, because the replay benchmarks run on any engine. Applying Wasm-R3 to web-based Wasm applications in the wild demonstrates the correctness of our approach as well as the effectiveness of our optimizations, which reduce the recorded traces by 99.53\% and the size of the replay benchmark by 9.98\%. We release the resulting benchmark suite of 27 applications, called Wasm-R3-Bench, to the community, to inspire a new generation of realistic and standalone Wasm benchmarks.},
  articleno     = {347},
  numpages      = {27},
  keywords      = {Benchmarking, WebAssembly, record and replay},
}

@article{banerjee:2024:skill-v-chance-card-board-games,
  title         = {Skill vs. Chance Quantification for Popular Card {\&} Board Games},
  author        = {Tathagata Banerjee and Anushka De and Subhamoy Maitra and Diganta Mukherjee},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2410.14363},
  doi           = {10.48550/ARXIV.2410.14363},
  url           = {https://doi.org/10.48550/arXiv.2410.14363},
  eprinttype    = {arXiv},
  eprint        = {2410.14363},
}

@inproceedings{barrish:2023:making-superhuman-ai-more-human,
  title         = {Making Superhuman {AI} More Human in Chess},
  author        = {Daniel Barrish and Steve Kroon and Brink van der Merwe},
  year          = {2023},
  booktitle     = {Advances in Computer Games - 18th International Conference, {ACG} 2023, Virtual Event, November 28-30, 2023, Revised Selected Papers},
  publisher     = {Springer},
  series        = {Lecture Notes in Computer Science},
  volume        = {14528},
  pages         = {3--14},
  doi           = {10.1007/978-3-031-54968-7\_1},
  url           = {https://doi.org/10.1007/978-3-031-54968-7\_1},
  editor        = {Michael Hartisch and Chu{-}Hsuan Hsueh and Jonathan Schaeffer},
  abstract      = {Computer chess research has traditionally focused on creating the strongest possible chess engine. Recently, however, attempts have been made to create engines that mimic the playing strength and style of human players. Our research proposes enhancements of models developed in this vein that more accurately imitate master-level players, as well as improve the prediction accuracy of existing models on weaker players. Our proposed enhancements are simple to apply by post-processing the output of existing chess engines. The performance of our enhancements was evaluated and compared using two metrics, prediction accuracy and average centipawn loss. We found that using an ensemble model over search depths maximised prediction accuracy, while an evaluation window filtering approach was preferable with respect to average centipawn loss.},
  keywords      = {Artificial intelligence, Chess, Action prediction},
}

@article{bart:2023:can-artificial-intelligence-identify-creativity,
  title         = {Can artificial intelligence identify creativity?: An empirical study},
  author        = {William Bart},
  year          = {2023},
  journal       = {Journal of Creativity},
  volume        = {33},
  number        = {2},
  pages         = {100057},
  doi           = {https://doi.org/10.1016/j.yjoc.2023.100057},
  issn          = {2713-3745},
  url           = {https://www.sciencedirect.com/science/article/pii/S271337452300016X},
  keywords      = {Chess, Creative move, Creativity, Stockfish 15, Artificial intelligence},
  abstract      = {This article reports an investigation of the extent to which a chess program with an artificial intelligence component (i.e., Stockfish with NNUE) can identify 10 chess moves that are recognized as outstanding chess moves. Stockfish with NNUE was able to identify seven of the ten moves. Although Stockfish with NNUE is a very powerful chess program, it has some limitations in identifying creative chess moves. There is a discussion of those limitations.},
}

@phdthesis{beliaev:2024:robust-cooperative-learning-algorithms,
  title         = {Towards Robust and Cooperative Learning Algorithms},
  author        = {Beliaev, Mark},
  year          = {2024},
  note          = {https://escholarship.org/uc/item/6mc2d7q3},
  school        = {UC Santa Barbara},
  annote        = {
    Recent progress in machine learning has been fueled by increasing scale, enabling breakthroughs in domains such as image generation, natural language understanding, and decision-making. While tremendous improvements have been realized for low-risk applications like chat completion and recommendation, there are fundamental challenges that need to be addressed for high-risk applications like robotics and security. Specifically, this thesis is motivated by the following issues: (1) Collecting large datasets often relies on crowdsourcing, which inevitably introduces heterogeneous and potentially suboptimal data. (2) Applications that require coordination between multiple agents are often coupled with risk, making it challenging to use decentralized learning algorithms. (3) While neural networks have demonstrated tremendous predictive capabilities, they are inherently fragile to adversarial attacks. In this thesis, we present algorithms for combatting these challenges within the domains of Reinforcement Learning and Adversarial Machine Learning.

    The first contribution introduces two algorithms for imitation learning in suboptimal settings, demonstrating that by modeling the suboptimalities present, we can improve the learning framework. The second contribution proposes a mechanism to encourage cooperation in multi-agent reinforcement learning, demonstrating that by allowing agents to gift part of their reward, we can promote prosocial behavior in a decentralized fashion. The third contribution develops a robust classification algorithm designed for sparse attacks, demonstrating that by extending our theoretical insights from idealized settings, we can combat adversarial attacks in neural network classifiers. We test our proposed algorithms across applications in image-classification, game-playing, and robotics. Together, these contributions aim to advance the deployment of machine learning in real-world scenarios by considering practical problem settings, presenting novel theoretical and algorithmic insights, and validating these findings empirically.
  },
  type          = {Doctoral Thesis},
}

@inproceedings{bertrand:2023:limitations-elo-real-world-games-transitive-not-additive,
  title         = {On the Limitations of the Elo, Real-World Games are Transitive, not Additive},
  author        = {Quentin Bertrand and Wojciech Marian Czarnecki and Gauthier Gidel},
  year          = {2023},
  booktitle     = {International Conference on Artificial Intelligence and Statistics, 25-27 April 2023, Palau de Congressos, Valencia, Spain},
  publisher     = {{PMLR}},
  series        = {Proceedings of Machine Learning Research},
  volume        = {206},
  pages         = {2905--2921},
  url           = {https://proceedings.mlr.press/v206/bertrand23a.html},
  editor        = {Francisco J. R. Ruiz and Jennifer G. Dy and Jan{-}Willem van de Meent},
}

@inproceedings{biemer:2024:solution-path-heuristics-predicting-difficulty-enjoyment-ratings-roguelike-level-segments,
  title         = {Solution Path Heuristics for Predicting Difficulty and Enjoyment Ratings of Roguelike Level Segments},
  author        = {Biemer, Colan and Cooper, Seth},
  year          = {2024},
  booktitle     = {Proceedings of the 19th International Conference on the Foundations of Digital Games},
  location      = {Worcester, MA, USA},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {FDG '24},
  doi           = {10.1145/3649921.3659846},
  isbn          = {9798400709555},
  url           = {https://doi.org/10.1145/3649921.3659846},
  abstract      = {When generating levels, algorithmically evaluating the results is essential. In this paper, we looked at predicting a level's difficulty and enjoyment. Past work has approached this problem for puzzle games like Sudoku by analyzing the characteristics of the initial level, the solved level, and the process that led to that solution. In this work, we examined a set of heuristics for Roguelike levels and their solutions, and their relationship to subjective player ratings of the levels. We gathered ratings of difficulty and enjoyment of levels in a study with 143 players. We ran an ablation study on the set of heuristics to find the best combination of heuristics for predicting difficulty and enjoyment with a linear regression model, and found solution path-based heursitics performed well. However, these models did not outperform a simple baseline for predicting enjoyment. Jaccard similarity on paths--a method we have not seen used in the field of game AI--was a useful predictor of difficulty. Testing proximity to enemies across a solution path is the only heuristic needed to predict how enjoyable a level will be.},
  articleno     = {69},
  numpages      = {8},
  keywords      = {difficulty, player study, procedural content generation},
}

@inproceedings{bizjak:2021:automatic-recognition-similar-chess-motifs,
  title         = {Automatic Recognition of Similar Chess Motifs},
  author        = {Bizjak, Miha and Guid, Matej},
  year          = {2021},
  booktitle     = {Advances in Computer Games: 17th International Conference, ACG 2021, Virtual Event, November 23–25, 2021, Revised Selected Papers},
  publisher     = {Springer-Verlag},
  address       = {Berlin, Heidelberg},
  pages         = {131–141},
  doi           = {10.1007/978-3-031-11488-5_12},
  isbn          = {978-3-031-11487-8},
  url           = {https://doi.org/10.1007/978-3-031-11488-5_12},
  abstract      = {We present a novel method to find chess positions similar to a given query position from a collection of chess games. We consider not only the static similarity resulting from the arrangement of chess pieces, but also the dynamic similarity involving the recognition of chess motifs and the tactical, dynamic aspects of position similarity. By encoding chess tactical problems as text documents, we use information retrieval techniques to enable efficient approximate searches. We have also developed a method for automatically generating tactical puzzles from a collection of chess games. We have experimentally shown the importance of including both static and dynamic features for successful recognition of similar chess motifs. The experiments have clearly shown that dynamic similarity plays a very important role in the evaluation of the similarity of chess motifs by both the program and chess experts.},
  numpages      = {11},
  keywords      = {Problem solving, Chess motifs, Automatic similarity recognition},
}

@inproceedings{bjorkqvist:2024:estimating-puzzlingness-chess-puzzles,
  title         = {{Estimating the Puzzlingness of Chess Puzzles}},
  author        = {Sebastian Bj\"{o}rkqvist},
  year          = {2024},
  booktitle     = {{IEEE} International Conference on Big Data, Big Data 2024, Washington DC, USA, December 15-18, 2024},
  publisher     = {{IEEE}},
}

@thesis{bos:2021:improving-chess-elo-system-process-mining,
  title         = {Improving the Chess Elo System With Process Mining},
  author        = {Niels Bos},
  year          = {2021},
  month         = {July},
  url           = {http://essay.utwente.nl/88571/},
  type          = {Bachelor's thesis},
  supervisor    = {Faiza Allah Bukhsh},
  abstract      = {Over the last decade, the amount of data generated by software applications e.g. information systems, websites, mobile applications etc. has increased tremendously. Process mining, a subdiscipline of data science, uses this data to analyse and improve processes. In this research, the possibilities of process mining on chess event logs are explored, to ultimately improve the chess Elo system. The chess Elo system is a widely used and well accepted rating system. The Elo system is, however,  flawed in multiple ways. Two major flaws of the Elo system, are its incapability to review a player?s strength and the excessive time needed to gain the appropriate Elo rating. This research explores the potential of process mining to identify chess expertise. To be more specific, multiple process mining techniques are applied on chess event logs, and the generated process models are analysed to identify chess expertise. This research presents a method to analyse the differences between high and low rated players. This is achieved by comparing process models generated from high and low rated chess games. The results show that by comparing the process models differences between high and low rated players can be observed. Process mining is therefore a promising approach to improve the Elo system and might be applicable to other software too. However, only the first twelve moves of a game were used. To gain more insight into the differences between high and low rated players, the mid and end games should be included in the event logs as well. Future research should be conducted with more chess games added to the event logs to increase the validity.},
}

@inproceedings{chen:2025:strength-estimation-human-like-strength-adjustment-games,
  title         = {Strength Estimation and Human-Like Strength Adjustment in Games},
  author        = {Chun Jung Chen and Chung-Chin Shih and Ti-Rong Wu},
  year          = {2025},
  booktitle     = {The Thirteenth International Conference on Learning Representations},
  url           = {https://openreview.net/forum?id=CvjXlsBLCX},
  abstract      = {Strength estimation and adjustment are crucial in designing human-AI interactions, particularly in games where AI surpasses human players. This paper introduces a novel strength system, including a strength estimator (SE) and an SE-based Monte Carlo tree search, denoted as SE-MCTS, which predicts strengths from games and offers different playing strengths with human styles. The strength estimator calculates strength scores and predicts ranks from games without direct human interaction. SE-MCTS utilizes the strength scores in a Monte Carlo tree search to adjust playing strength and style. We first conduct experiments in Go, a challenging board game with a wide range of ranks. Our strength estimator significantly achieves over 80\% accuracy in predicting ranks by observing 15 games only, whereas the previous method reached 49\% accuracy for 100 games. For strength adjustment, SE-MCTS successfully adjusts to designated ranks while achieving a 51.33\% accuracy in aligning to human actions, outperforming a previous state-of-the-art, with only 42.56\% accuracy. To demonstrate the generality of our strength system, we further apply SE and SE-MCTS to chess and obtain consistent results. These results show a promising approach to strength estimation and adjustment, enhancing human-AI interactions in games. Our code is available at https://rlg.iis.sinica.edu.tw/papers/strength-estimator.},
  tldr          = {This paper proposes a strength system that can estimate the strength from games and provide various playing strengths while simultaneously offer a human-like behavior in both Go and chess.},
  keywords      = {Bradley-Terry Model, Strength Estimation, Strength Adjustment, Human-like Playing Style, Monte-Carlo Tree Search, Go, Chess},
  github        = {https://github.com/rlglab/strength-estimator/},
  website       = {https://rlg.iis.sinica.edu.tw/papers/strength-estimator/},
}

@inproceedings{cheong:2025:design-electronic-chess-board-analogue-hall-effect-sensors-piece-identification,
  title         = {Design of Electronic Chess Board Using Analogue Hall-effect Sensors for Piece Identification},
  author        = {Cheong, Justin Julius Chin and Bhatia, Praneel and Krauledat, Matthias and Hartanto, Ronny},
  year          = {2025},
  booktitle     = {2025 7th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (ICHORA)},
  pages         = {1--5},
  doi           = {10.1109/ICHORA65333.2025.11016842},
  keywords      = {Magnetic flux density;Magnetic sensors;Printed circuits;Interference;Sensor phenomena and characterization;Robot sensing systems;Sensor systems;Sensors;Reliability;Magnets;electronic chessboard;analogue object identification;Hall-effect sensors;micro-controller},
}

@misc{choudhary:2025:human-chess-novel-searchless-rl-chess-agent-capable-multi-elo-human-like-play,
  title         = {Human Chess: A Novel Searchless RL-based Chess Agent Capable of Multi-ELO Human-Like Play},
  author        = {Choudhary, Prerit and Vagadia, Rikhil and Dhawan, Ankush},
  year          = {2025},
  url           = {https://cs224r.stanford.edu/projects/pdfs/CS224R_Final_Report__1_%20(3).pdf},
  note          = {Final project for CS 224R Deep Reinforcement Learning, Spring 2025 https://cs224r.stanford.edu/projects/cs224r\_final\_projects.html},
}

@article{chowdhary:2023:quantifying-human-performance-chess,
  title         = {Quantifying human performance in chess},
  author        = {Chowdhary, Sandeep and Iacopini, Iacopo and Battiston, Federico},
  year          = {2023},
  month         = {Feb},
  day           = {06},
  journal       = {Scientific Reports},
  volume        = {13},
  number        = {1},
  pages         = {2113},
  doi           = {10.1038/s41598-023-27735-9},
  issn          = {2045-2322},
  url           = {https://doi.org/10.1038/s41598-023-27735-9},
  abstract      = {From sports to science, the recent availability of large-scale data has allowed to gain insights on the drivers of human innovation and success in a variety of domains. Here we quantify human performance in the popular game of chess by leveraging a very large dataset comprising of over 120 million games between almost 1 million players. We find that individuals encounter hot streaks of repeated success, longer for beginners than for expert players, and even longer cold streaks of unsatisfying performance. Skilled players can be distinguished from the others based on their gaming behaviour. Differences appear from the very first moves of the game, with experts tending to specialize and repeat the same openings while beginners explore and diversify more. However, experts experience a broader response repertoire, and display a deeper understanding of different variations within the same line. Over time, the opening diversity of a player tends to decrease, hinting at the development of individual playing styles. Nevertheless, we find that players are often not able to recognize their most successful openings. Overall, our work contributes to quantifying human performance in competitive settings, providing a first large-scale quantitative analysis of individual careers in chess, helping unveil the determinants separating elite from beginner performance.},
}

@article{chowdhury:2021:predicting-chess-openings-modelling-opponents,
  title         = {Predicting Chess Opening Through Modelling Of Chess Opponents},
  author        = {Chowdhury, Debarpan Bose and Sen, Banashree},
  year          = {2021},
  journal       = {Webology (ISSN: 1735-188X)},
  volume        = {18},
  number        = {6},
}

@inproceedings{comarela:2021:lightweight-approach-prediction-errors-chess,
  title         = {A lightweight approach for predicting errors in chess matches},
  author        = {Giovanni Comarela and Davi Silva},
  year          = {2021},
  booktitle     = {Anais do XVIII Encontro Nacional de Intelig\^{e}ncia Artificial e Computacional},
  location      = {Evento Online},
  publisher     = {SBC},
  address       = {Porto Alegre, RS, Brasil},
  pages         = {703--714},
  doi           = {10.5753/eniac.2021.18296},
  issn          = {2763-9061},
  url           = {https://sol.sbc.org.br/index.php/eniac/article/view/18296},
}

@article{cook:2025:advantage-moving-first-amateur-online-chess,
  title         = {The Advantage of Moving First in Amateur Online Chess},
  author        = {Tyler Cook},
  year          = {2025},
  journal       = {ICGA Journal},
  doi           = {10.1177/13896911251315903},
  url           = {https://doi.org/10.1177/13896911251315903},
  abstract      = {There is a long-held belief in the chess community that the player with the white pieces has an advantage in making the first move. This phenomenon has been observed repeatedly in over-the-board games between high-level players and professionals. However, less is known about the prevalence of white's advantage in games played between amateurs in more casual settings. This article attempts to identify a first-move advantage in chess by examining a large database of amateur games played online on a dedicated chess website. Win rates are calculated for various rating levels, and the influence of opening move choice is also explored. These results can help determine whether there is an inherent first-move advantage in chess observable for all players in multiple settings, or if this effect is exclusively seen with players of high skill during games played in person.},
}

@article{cruz:2025:understanding-learned-look-ahead-behavior-chess-neural-networks,
  title         = {Understanding the learned look-ahead behavior of chess neural networks},
  author        = {Diogo Cruz},
  year          = {2025},
  journal       = {CoRR},
  volume        = {abs/2505.21552},
  doi           = {10.48550/ARXIV.2505.21552},
  url           = {https://doi.org/10.48550/arXiv.2505.21552},
  note          = {keywords from rejected openreview submission: https://openreview.net/forum?id=OcBAd0JPxv\&noteId=ZcMfmDpMpn},
  eprinttype    = {arXiv},
  eprint        = {2505.21552},
  abstract      = {We investigate the look-ahead capabilities of chess-playing neural networks, specifically focusing on the Leela Chess Zero policy network. We build on the work of Jenner et al. (2024) by analyzing the model's ability to consider future moves and alternative sequences beyond the immediate next move. Our findings reveal that the network's look-ahead behavior is highly context-dependent, varying significantly based on the specific chess position. We demonstrate that the model can process information about board states up to seven moves ahead, utilizing similar internal mechanisms across different future time steps. Additionally, we provide evidence that the network considers multiple possible move sequences rather than focusing on a single line of play. These results offer new insights into the emergence of sophisticated look-ahead capabilities in neural networks trained on strategic tasks, contributing to our understanding of AI reasoning in complex domains. Our work also showcases the effectiveness of interpretability techniques in uncovering cognitive-like processes in artificial intelligence systems.},
  keywords      = {model behavior attribution, look-ahead planning, mechanistic interpretability},
}

@article{czech:2020:learning-crazyhouse-above-world-champion-deep-neural-networks-human-data,
  title         = {Learning to Play the Chess Variant Crazyhouse Above World Champion Level With Deep Neural Networks and Human Data},
  author        = {Johannes Czech and Moritz Willig and Alena Beyer and Kristian Kersting and Johannes F{\"{u}}rnkranz},
  year          = {2020},
  journal       = {Frontiers Artif. Intell.},
  volume        = {3},
  pages         = {24},
  doi           = {10.3389/FRAI.2020.00024},
  url           = {https://doi.org/10.3389/frai.2020.00024},
}

@inproceedings{czech:2021:improving-alphazero-monte-carlo-graph-search,
  title         = {Improving AlphaZero Using Monte-Carlo Graph Search},
  author        = {Johannes Czech and Patrick Korus and Kristian Kersting},
  year          = {2021},
  booktitle     = {Proceedings of the Thirty-First International Conference on Automated Planning and Scheduling, {ICAPS} 2021, Guangzhou, China (virtual), August 2-13, 2021},
  publisher     = {{AAAI} Press},
  pages         = {103--111},
  url           = {https://ojs.aaai.org/index.php/ICAPS/article/view/15952},
  editor        = {Susanne Biundo and Minh Do and Robert Goldman and Michael Katz and Qiang Yang and Hankz Hankui Zhuo},
}

@inproceedings{das:2020:leveraging-rationales-human-task-performance,
  title         = {Leveraging rationales to improve human task performance},
  author        = {Das, Devleena and Chernova, Sonia},
  year          = {2020},
  booktitle     = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
  location      = {Cagliari, Italy},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {IUI '20},
  pages         = {510–518},
  doi           = {10.1145/3377325.3377512},
  isbn          = {9781450371186},
  url           = {https://doi.org/10.1145/3377325.3377512},
  abstract      = {Machine learning (ML) systems across many application areas are increasingly demonstrating performance that is beyond that of humans. In response to the proliferation of such models, the field of Explainable AI (XAI) has sought to develop techniques that enhance the transparency and interpretability of machine learning methods. In this work, we consider a question not previously explored within the XAI and ML communities: Given a computational system whose performance exceeds that of its human user, can explainable AI capabilities be leveraged to improve the performance of the human? We study this question in the context of the game of Chess, for which computational game engines that surpass the performance of the average player are widely available. We introduce the Rationale-Generating Algorithm, an automated technique for generating rationales for utility-based computational methods, which we evaluate with a multi-day user study against two baselines. The results show that our approach produces rationales that lead to statistically significant improvement in human task performance, demonstrating that rationales automatically generated from an AI's internal task model can be used not only to explain what the system is doing, but also to instruct the user and ultimately improve their task performance.},
  numpages      = {9},
  keywords      = {explainable AI, machine learning},
}

@inproceedings{davis:2024:decoding-chess-mastery-mechanistic-analysis-chess-language-transformer-model,
  title         = {Decoding Chess Mastery: A Mechanistic Analysis of a Chess Language Transformer Model},
  author        = {Davis, Austin L. and Sukthankar, Gita},
  year          = {2024},
  booktitle     = {Artificial General Intelligence: 17th International Conference, AGI 2024, Seattle, WA, USA, August 13–16, 2024, Proceedings},
  location      = {SEATTLE, WA, USA},
  publisher     = {Springer-Verlag},
  address       = {Berlin, Heidelberg},
  pages         = {63–72},
  doi           = {10.1007/978-3-031-65572-2_7},
  isbn          = {978-3-031-65571-5},
  url           = {https://doi.org/10.1007/978-3-031-65572-2_7},
  abstract      = {Mechanistic interpretability (MI) studies aim to identify the specific neural pathways that underlie decision-making in neural networks. Here we analyze both the horizontal and vertical information flows of a chess-playing transformer. This paper introduces a new taxonomy of chessboard attention patterns that synchronize to guide move selection. Our findings show that the early layers of the chess transformer correctly identify moves that are highly ranked by the final layer. Experiments conducted on human chess players laid the foundation for much of our current understanding of human problem-solving, cognition, and visual memory. We believe that the study of chess language transformers may be an equally fruitful research area for AGI systems.},
  numpages      = {10},
  keywords      = {chess cognition, mechanistic interpretability, transformers},
}

@inproceedings{davis:2024:performance-envelopes-linear-probes-latent-representation-edits-gpt-models,
  title         = {Performance Envelopes of Linear Probes for Latent Representation Edits in GPT Models},
  author        = {Davis, Austin L and Sukthankar, Gita},
  year          = {2024},
  booktitle     = {2024 International Conference on Machine Learning and Applications (ICMLA)},
  keywords      = {Representation Engineering; Probing Classifiers; Chess-playing Language Models, GPT},
}

@thesis{davis:2025:interpreation-control-ai-model-behavior-direct-adjustment-latent-representations,
  title         = {Interpretation and Control of AI Model Behavior Through Direct Adjustment of Latent Representations},
  author        = {Davis, Austin},
  year          = {2025},
  url           = {https://stars.library.ucf.edu/etd2024/285},
  institution   = {University of Central Florida},
  type          = {PhD thesis},
  supervisor    = {Sukthankar, Gita},
  keywords      = {Latent Representation Editing; Mechanistic Interpretability; Linear Probes; Chess Language Models; Artificial Intelligence},
  abstract      = {
    This dissertation investigates the structures and mechanisms underpinning the latent space representations that emerge within Generative Pretrained Transformer (GPT) models. Addressing the broader goal of enhancing AI trustworthiness through transparency, accountability, and controllability, we focus on techniques to understand, quantify, and manipulate these latent space representations. Through a series of analyses, we examine several chess-playing GPT models as controlled testbeds, leveraging their structured decision space to explore emergent representations and decision-making processes.

    Key contributions include a mechanistic analysis of the attention heads and latent representations, the development of novel metrics for evaluating intervention outcomes, and the application of linear probe classifiers to decode and edit the model's internal world representations. Analysis of the probe weight vectors reveals that the chess-playing GPT developed an emergent world model of the game that includes pieces, positions, and movement rules, and provides empirical support for the linear representation hypothesis--the idea that abstract concepts are encoded as specific directions in the model's hidden state space. Complementary analysis of the hidden state vectors demonstrates that the model's internal representations honor the Markovian property of chess.

    Experimental results demonstrate that linear interventions can causally steer GPT outputs while preserving their semantic validity. Drawing on the dose-response analogy from medicine, we vary both the strength and position of interventions, showing that output quality is maximized when intervention strength follows an exponentially decaying schedule across token positions. Similar experiments using sparse autoencoders in place of linear probes yielded significantly poorer performance. These results highlight the effectiveness of simple linear probes as valuable tools for interpretability and control.
  },
}

@article{de-marzo:2023:complexity-similarity-chess-openings-community-data,
  title         = {Quantifying the complexity and similarity of chess openings using online chess community data},
  author        = {De Marzo, Giordano and Servedio, Vito D. P.},
  year          = {2023},
  month         = {Apr},
  day           = {01},
  journal       = {Scientific Reports},
  volume        = {13},
  number        = {1},
  pages         = {5327},
  doi           = {10.1038/s41598-023-31658-w},
  issn          = {2045-2322},
  url           = {https://doi.org/10.1038/s41598-023-31658-w},
  abstract      = {Chess is a centuries-old game that continues to be widely played worldwide. Opening Theory is one of the pillars of chess and requires years of study to be mastered. In this paper, we use the games played in an online chess platform to exploit the ``wisdom of the crowd'' and answer questions traditionally tackled only by chess experts. We first define a relatedness network of chess openings that quantifies how similar two openings are to play. Using this network, we identify communities of nodes corresponding to the most common opening choices and their mutual relationships. Furthermore, we demonstrate how the relatedness network can be used to forecast future openings players will start to play, with back-tested predictions outperforming a random predictor. We then apply the Economic Fitness and Complexity algorithm to measure the difficulty of openings and players' skill levels. Our study not only provides a new perspective on chess analysis but also opens the possibility of suggesting personalized opening recommendations using complex network theory.},
}

@inproceedings{de-sa-delgado-neto:2019:chess-position-identification,
  title         = {Chess Position Identification using Pieces Classification Based on Synthetic Images Generation and Deep Neural Network Fine-Tuning},
  author        = {de S\'{a} Delgado Neto, Afonso and Mendes Campello, Rafael},
  year          = {2019},
  booktitle     = {2019 21st Symposium on Virtual and Augmented Reality (SVR)},
  pages         = {152--160},
  doi           = {10.1109/SVR.2019.00038},
  keywords      = {Histograms, Image color analysis, Games, Tracking, Image edge detection, Machine learning, Task analysis, chess, neural networks, piece recognition, synthetic data generation},
}

@misc{deletang:2024:generative-reinforcement-learning-with-transformers,
  title         = {Generative Reinforcement Learning with Transformers},
  author        = {Gregoire Deletang and Anian Ruoss and Li Kevin Wenliang and Elliot Catt and Tim Genewein and Jordi Grau-Moya and Marcus Hutter and Joel Veness},
  year          = {2024},
  url           = {https://openreview.net/forum?id=6qtDu7hVPF},
}

@inproceedings{demeter:2021:probing-learning-representation-language-models-closed-domains,
  title         = {Who{'}s on First?: Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains},
  author        = {Demeter, David  and Downey, Doug},
  year          = {2021},
  month         = nov,
  booktitle     = {Proceedings of the 25th Conference on Computational Natural Language Learning},
  publisher     = {Association for Computational Linguistics},
  address       = {Online},
  pages         = {210--222},
  doi           = {10.18653/v1/2021.conll-1.16},
  url           = {https://aclanthology.org/2021.conll-1.16},
  editor        = {Bisazza, Arianna  and Abend, Omri},
  abstract      = {The capabilities of today{'}s natural language processing systems are typically evaluated using large datasets of curated questions and answers. While these are critical benchmarks of progress, they also suffer from weakness due to artificial distributions and incomplete knowledge. Artifacts arising from artificial distributions can overstate language model performance, while incomplete knowledge limits fine-grained analysis. In this work, we introduce a complementary benchmarking approach based on SimPlified Language Activity Traces (SPLAT). SPLATs are corpora of language encodings of activity in some closed domain (we study traces from chess and baseball games in this work). SPLAT datasets use naturally-arising distributions, allow the generation of question-answer pairs at scale, and afford complete knowledge in their closed domains. We show that language models of three different architectures can answer questions about world states using only verb-like encodings of activity. Our approach is extensible to new language models and additional question-answering tasks.},
}

@inproceedings{diallo:2025:chessmovellm-large-language-models-chess-next-move-prediction,
  title         = {ChessMoveLLM: Large Language Models for Chess Next Move Prediction},
  author        = {Diallo, Kassim B. and Akhloufi, Moulay A.},
  year          = {2025},
  booktitle     = {SoutheastCon 2025},
  pages         = {475--480},
  doi           = {10.1109/SoutheastCon56624.2025.10971611},
  keywords      = {Training, Deep learning, Social networking (online), Large language models, Retrieval augmented generation, Force, Transformers, Logic, Engines, Tuning, Deep learning, Transformers ,LLMs, RAG, FAISS, GPT, Similarity Search, Chess engine, Fine tuning},
}

@inproceedings{ding:2024:easy2hard-bench,
  title         = {Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization},
  author        = {Ding, Mucong and Deng, Chenghao and Choo, Jocelyn and Wu, Zichu and Agrawal, Aakriti and Schwarzschild, Avi and Zhou, Tianyi and Goldstein, Tom and Langford, John and Anandkumar, A. and Huang, Furong},
  year          = {2024},
  month         = {September},
  booktitle     = {NeurIPS 2024},
  url           = {https://www.microsoft.com/en-us/research/publication/easy2hard-bench-standardized-difficulty-labels-for-profiling-llm-performance-and-generalization/},
  abstract      = {While generalization over tasks from easy to hard is crucial to profile language models (LLMs), the datasets with fine-grained difficulty annotations for each problem across a broad range of complexity are still blank. Aiming to address this limitation, we present Easy2Hard-Bench, a consistently formatted collection of 6 benchmark datasets spanning various domains, such as mathematics and programming problems, chess puzzles, and reasoning questions. Each problem within these datasets is annotated with numerical difficulty scores. To systematically estimate problem difficulties, we collect abundant performance data on attempts to each problem by humans in the real world or LLMs on the prominent leaderboard. Leveraging the rich performance data, we apply well-established difficulty ranking systems, such as Item Response Theory (IRT) and Glicko-2 models, to uniformly assign numerical difficulty scores to problems. Moreover, datasets in Easy2Hard-Bench distinguish themselves from previous collections by a higher proportion of challenging problems. Through extensive experiments with six state-of-the-art LLMs, we provide a comprehensive analysis of their performance and generalization capabilities across varying levels of difficulty, with the aim of inspiring future research in LLM generalization. The datasets are available at https://huggingface.co/datasets/furonghuang-lab/Easy2Hard-Bench.},
}

@inbook{divakaran:2025:data-serializaiton-persistence-deep-dive-python-techniques-best-practices-developers,
  title         = {Data Serialization and Persistence},
  author        = {Divakaran, Adarsh},
  year          = {2025},
  booktitle     = {Deep Dive Python: Techniques and Best Practices for Developers},
  publisher     = {Apress},
  address       = {Berkeley, CA},
  pages         = {531--588},
  doi           = {10.1007/979-8-8688-1261-3_17},
  isbn          = {979-8-8688-1261-3},
  url           = {https://doi.org/10.1007/979-8-8688-1261-3_17},
}

@article{eisma:2024:turing-tests-chess-human-subjectivity,
  title         = {Turing Tests in Chess: An Experiment Revealing the Role of Human Subjectivity},
  author        = {Yke Bauke Eisma and Robin Koerts and Joost {de Winter}},
  year          = {2024},
  journal       = {Computers in Human Behavior Reports},
  pages         = {100496},
  doi           = {https://doi.org/10.1016/j.chbr.2024.100496},
  issn          = {2451-9588},
  url           = {https://www.sciencedirect.com/science/article/pii/S2451958824001295},
  abstract      = {With the growing capabilities of AI, technology is increasingly able to match or even surpass human performance. In the current study, focused on the game of chess, we investigated whether chess players could distinguish if they were playing against a human or a computer, and how they achieved this. A total of 24 chess players each played eight 5+0 Blitz games from different starting positions. They played against (1) a human, (2) Maia, a neural network-based chess engine trained to play in a human-like manner, (3) Stockfish 16, the best chess engine available, downgraded to play at a lower level, and (4) Stockfish 16 at its maximal level. The opponent's move time was fixed at 10 seconds. During the game, participants verbalized their thoughts, and after each game, they indicated by means of a questionnaire whether they thought they had played against a human or a machine and if there were particular moves that revealed the nature of the opponent. The results showed that Stockfish at the highest level was usually correctly identified as an engine, while Maia was often incorrectly identified as a human. The moves of the downgraded Stockfish were relatively often labeled as `strange' by the participants. In conclusion, the Turing test, as applied here in a domain where computers can perform superhumanly, is essentially a test of whether the chess computer can devise suboptimal moves that correspond to human moves, and not necessarily a test of computer intelligence.},
}

@inproceedings{feng:2023:chessgpt-policy-learning-language-modeling,
  title         = {ChessGPT: Bridging Policy Learning and Language Modeling},
  author        = {Xidong Feng and Yicheng Luo and Ziyan Wang and Hongrui Tang and Mengyue Yang and Kun Shao and David Mguni and Yali Du and Jun Wang},
  year          = {2023},
  booktitle     = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
  url           = {http://papers.nips.cc/paper\_files/paper/2023/hash/16b14e3f288f076e0ca73bdad6405f77-Abstract-Datasets\_and\_Benchmarks.html},
  editor        = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
}

@misc{gee:2025:investigating-experiential-effects-online-chess-hierarchical-bayesian-analysis,
  title         = {Investigating Experiential Effects in Online Chess using a Hierarchical Bayesian Analysis},
  author        = {Adam Gee and Sydney O. Seese and James P. Curley and Owen G. Ward},
  year          = {2025},
  url           = {https://arxiv.org/abs/2503.21713},
  eprint        = {2503.21713},
  archiveprefix = {arXiv},
  primaryclass  = {stat.AP},
}

@article{ghayebzadeh:2025:effect-transcranial-current-decision-making-chess-personality,
  title         = {The Effect of Transcranial Direct Current Stimulation on Risky Decision-Making of Student Chess Players Based on their Introverted and Extroverted Personality Traits},
  author        = {Ghayebzadeh, Shahrouz and Moharramzadeh, Mehrdad and Zoghi, Maryam},
  year          = {2025},
  journal       = {Sport Psychology Studies},
  publisher     = {Sport Sciences Research institute},
  doi           = {10.22089/spsyj.2025.17731.2546},
  issn          = {2345-2978},
  url           = {https://spsyj.ssrc.ac.ir/article_4394_55f2b660d8300f25206eb52a483e0bb4.pdf},
  eissn         = {2538-1504},
  abstract      = {The aim of this research was to investigate the effects of transcranial direct current stimulation (tDCS) on risky decision-making in student chess players, taking into account their personality traits. In this study, 28 high school students who were active in chess and participated in provincial and national chess leagues were selected. Based on the NEO Five-Factor Inventory of personality traits, they were divided into two groups: 14 extroverted students (17 \pm{} 0.88) and 14 introverted students (16.5 \pm{} 1.02). Each participant attended three separate sessions in the laboratory, with a minimum 72-hour rest period between sessions. In each session, participants performed the Iowa Gambling Task and the Lichess computer game before any stimulation. They were then subjected to one of three conditions: right anodal/left cathodal, right cathodal/left anodal, or sham stimulation, for 20 minutes at 2 mA intensity over the dorsolateral prefrontal cortex. After the stimulation, participants repeated the Iowa Gambling Task and the Lichess computer game. Data analysis using two-way mixed ANOVA revealed a significant difference in the Iowa Gambling Task between right anodal/left cathodal and right cathodal/left anodal stimulation based on personality traits (p = 0.001). The findings of this study indicated that transcranial direct current stimulation had a differential effect on decision-making in chess players based on their personality traits. Specifically, the study's results showed that extroverted players exhibited more risk-taking behaviour, while introverted players acted more cautiously.},
  keywords      = {Extroverted,Brain stimulation,Risky Decision-making,Introverted,Chess},
}

@thesis{giadikiaroglou:2025:investgiating-capabilities-language-models-puzzles,
  title         = {Investigating the capabilities of language models in puzzle reasoning: A survey and experimental analysis},
  author        = {Giadikiaroglou, Panagiotis},
  year          = {2025},
  month         = mar,
  publisher     = {National Technological University of Athens},
  doi           = {http://dx.doi.org/10.26240/heal.ntua.29165},
  url           = {https://dspace.lib.ntua.gr/xmlui/handle/123456789/61469},
  supervisor    = {Giorgos Stamou},
  type          = {Bachelor's thesis},
  keywords      = {Large Language Models; Reasoning; Puzzle Solving; Prompting; Neurosymbolic Methods},
  abstract      = {Puzzle-solving has long served as a benchmark for evaluating artificial intelligence, testing a model's ability to reason, infer, and strategize across complex problem spaces. Traditional AI and machine learning methods, such as symbolic reasoning and reinforcement learning, have made notable strides in structured domains like board games and logic puzzles. However, as neural networks and, more recently, large language models (LLMs) have evolved, new possibilities have emerged for tackling a broader range of puzzle types, including those requiring nuanced commonsense reasoning, abstract pattern recognition, and complex multi-step calculations. LLMs, with their vast data-driven language capabilities, hold unique potential to bridge structured logical tasks and less formal, knowledge-based puzzles. Despite these advances, the current landscape of puzzle-solving with LLMs reveals both achievements and limitations, particularly when models are tasked with problems that demand interpretative reasoning and precise calculation. This thesis explores the evolving role of LLMs in solving such complex reasoning tasks, specifically focusing on their puzzle-solving capabilities. Divided into two main sections, the thesis first provides a comprehensive survey of recent advancements in LLM methodologies, covering diverse prompting techniques, neuro-symbolic approaches, and fine-tuning strategies for puzzles. Using a newly proposed taxonomy, puzzles are categorized into rule-based and rule-less types, with each category examined for its unique cognitive demands on LLMs. The second section presents experimental evaluations conducted on four datasets--two math-based datasets (GSM8K, SVAMP) and two puzzle-focused datasets (Game of 24 and RiddleSense). Various reasoning techniques, including Input-Output (IO) prompting, Chain-of-Thought (CoT), Least-to-Most (LtM), and Faithful-CoT methods, are employed to assess LLM performance. Models of varying scales, particularly smaller LLMs like Llama-3.1 family and Mistral, are tested across settings such as zero-shot, few-shot, and self-consistency to evaluate their efficacy in solving complex and multi-step reasoning tasks. The thesis provides critical insights into the performance limitations of current LLMs in puzzle-solving, particularly noting that advanced reasoning methods like Faithful-CoT and puzzle translation techniques yield inconsistent improvements with smaller models. Finally, it outlines future research directions, advocating for expanded dataset creation, neuro-symbolic integration, and advancements in puzzle generation. This thesis aims to deepen our understanding of LLMs' reasoning abilities and highlight pathways to enhance their performance in complex cognitive tasks.},
}

@inproceedings{guntz:2018:role-emotion-problem-solving,
  title         = {The role of emotion in problem solving: first results from observing chess},
  author        = {Thomas Guntz and James L. Crowley and Dominique Vaufreydaz and Raffaella Balzarini and Philippe Dessus},
  year          = {2018},
  booktitle     = {Proceedings of the Workshop on Modeling Cognitive Processes from Multimodal Data, MCPMD\@ICMI 2018, Boulder, CO, USA, October 16, 2018},
  publisher     = {{ACM}},
  pages         = {12},
  url           = {http://dl.acm.org/citation.cfm?id=3279846},
}

@article{gupta:2023:determining-chess-piece-values-machine-learning,
  title         = {Determining Chess Piece Values Using Machine Learning},
  author        = {Gupta, Aditya and Grattoni, Christopher and Gupta, Arnav},
  year          = {2023},
  month         = {Feb.},
  journal       = {Journal of Student Research},
  volume        = {12},
  number        = {1},
  doi           = {10.47611/jsrhs.v12i1.4356},
  url           = {https://www.jsr.org/hs/index.php/path/article/view/4356},
  place         = {Houston, USA},
  abstract      = {This paper attempts to generate point values for chess pieces, as alternatives to the commonly accepted chess piece values. We use a database of over a million online chess games to heuristically determine the value of a chess piece, by using material imbalances to predict game results. We then explore how piece values change when we analyze material imbalances at various stages of a chess game. As further exploration, we determine what practical values chess pieces and imbalances have at various rating ranges. This creates practical data that players of varying rating can use to aid in chess calculation, as opposed to the rigid values that are typically accepted.\&lt;/p\&gt;},
}

@article{helfenstein:2024:checkmating-one-many-mixture-of-experts-mcts-improve-chess,
  title         = {Checkmating One, by Using Many: Combining Mixture of Experts with {MCTS} to Improve in Chess},
  author        = {Felix Helfenstein and Jannis Bl{\"{u}}ml and Johannes Czech and Kristian Kersting},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2401.16852},
  doi           = {10.48550/ARXIV.2401.16852},
  url           = {https://doi.org/10.48550/arXiv.2401.16852},
  eprinttype    = {arXiv},
  eprint        = {2401.16852},
}

@inproceedings{holdaway:2021:risk-taking-adversarial-games-what-billion-chess-games-tell-us,
  title         = {Risk-taking in adversarial games: What can 1 billion online chess games tell us?},
  author        = {Cameron Holdaway and Ed Vul},
  year          = {2021},
  booktitle     = {Proceedings of the 43rd Annual Meeting of the Cognitive Science Society, CogSci 2021, virtual, July 26-29, 2021},
  publisher     = {cognitivesciencesociety.org},
  url           = {https://escholarship.org/uc/item/403764rd},
  editor        = {W. Tecumseh Fitch and Claus Lamm and Helmut Leder and Kristin Te{\ss}mar{-}Raible},
}

@mastersthesis{hoque:2022:classification-anomaly-detection-chess,
  title         = {Classification of Chess Games: An Exploration of Classifiers for Anomaly Detection in Chess},
  author        = {Hoque, Masudul},
  year          = {2021},
  note          = {https://cornerstone.lib.mnsu.edu/etds/1119/},
  school        = {Minnesota State University, Mankato},
  type          = {Master's thesis},
  annote        = {Chess is a strategy board game with its inception dating back to the 15th century. The Covid-19 pandemic has led to a chess boom online with 95,853,038 chess games being played during January, 2021 on lichess.com. Along with the chess boom, instances of cheating have also become more rampant. Classifications have been used for anomaly detection in different fields and thus it is a natural idea to develop classifiers to detect cheating in chess. However, there are no specific examples of this, and it is difficult to obtain data where cheating has occurred. So, in this paper, we develop 4 machine learning classifiers, Linear Discriminant Analysis, Quadratic Discriminant Analysis, Multinomial Logistic Regression, and K-Nearest Neighbour classifiers to predict chess game results and explore predictors that produce the best accuracy performance. We use Confusion Matrix, K Fold Cross-Validation, and Leave-One-Out Cross-Validation methods to find the accuracy metrics. There are three phases of analysis. In phase I, we train classifiers using 1.94 million over the board game as training data and 20 thousand online games as testing data and obtain accuracy metrics. In phase II, we select a smaller pool of 212 games, select additional predictor variables from chess engine evaluation of the moves played in those games and check whether the inclusion of the variables improve performance. Finally, in phase III, we investigate for patterns in misclassified cases to define anomalies. From phase I, the models are not performing at a utilizable level of accuracy (44-63\%). For all classifiers, it is no better than deciding the class with a coin toss. K-Nearest Neighbour with K = 7 was the best model. In phase II, adding the new predictors improved the performance of all the classifiers significantly across all validation methods. In fact, using only significant variables as predictors produced highly accurate classifiers. Finally, from phase III, we could not find any patterns or significant differences between the predictors for both correct classifications and misclassifications. In conclusion, machine learning classification is only one useful tool to spot instances that indicates anomalies. However, we cannot simply judge anomalous games using only this method.},
}

@misc{hull:2025:beyond-evaluation-learning-contextual-chess-position-representations,
  title         = {Beyond Evaluation: Learning Contextual Chess Position Representations},
  author        = {Ben Hull},
  year          = {2025},
  note          = {Technical report},
  howpublished  = {Accessed via \url{[https://bluehood.github.io/](https://bluehood.github.io/)}},
}

@misc{hwang:2025:can-large-language-models-develop-strategic-reasoning-post-training-insights-learning-chess,
  title         = {Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess},
  author        = {Dongyoon Hwang and Hojoon Lee and Jaegul Choo and Dongmin Park and Jongho Park},
  year          = {2025},
  url           = {https://arxiv.org/abs/2507.00726},
  eprint        = {2507.00726},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
}

@inproceedings{iavich:2024:detecting-fair-play-violations-chess-neural-networks,
  title         = {Detecting Fair Play Violations in Chess Using Neural Networks},
  author        = {Iavich, Maksim and Kevanishvili, Zura},
  year          = {2024},
  booktitle     = {Proceedings of 29th International Conference Information Society and University Studies},
  publisher     = {CEUR-WS.org},
  series        = {{CEUR} Workshop Proceedings},
  volume        = {3341},
  pages         = {121--127},
  url           = {https://ceur-ws.org/Vol-3885/paper13.pdf},
}

@inproceedings{jakub:2026:chessformer-modeling-human-decision-making-chess,
  title         = {ChessFormer - Modeling Human Decision Making in Chess},
  author        = {Zeman, Jakub and {\v{C}}epek, Miroslav},
  year          = {2026},
  booktitle     = {Modeling Decisions for Artificial Intelligence},
  publisher     = {Springer Nature Switzerland},
  address       = {Cham},
  pages         = {42--53},
  isbn          = {978-3-032-00891-6},
  editor        = {Torra, Vicen{\c{c}} and Narukawa, Yasuo and Domingo-Ferrer, Josep},
  abstract      = {ChessFormer introduces a novel searchless chess engine leveraging transformer architecture to approximate human decision-making in chess. Trained on a vast dataset of 3 billion chess positions, our model learns its entire decision-making process directly from training data. Evaluations show an improvement in human move-matching accuracy over prior models in high-Elo ranges and the model's ability to distinguish between human and algorithmic decision-making, offering potential applications in chess analysis or cheat detection.},
}

@article{jenner:2024:evidence-lookahead-chess-neural-network,
  title         = {Evidence of Learned Look-Ahead in a Chess-Playing Neural Network},
  author        = {Erik Jenner and Shreyas Kapur and Vasil Georgiev and Cameron Allen and Scott Emmons and Stuart Russell},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2406.00877},
  doi           = {10.48550/ARXIV.2406.00877},
  url           = {https://doi.org/10.48550/arXiv.2406.00877},
  eprinttype    = {arXiv},
  eprint        = {2406.00877},
}

@misc{jiang:2023:building-natural-language-chess-engine-pretraining-instruction-finetunine,
  title         = {Building a Natural Language Chess Engine with Pretraining and Instruction Fine-Tuning},
  author        = {Bowen Jiang},
  year          = {2023},
  url           = {https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1234/final-reports/final-report-169466939.pdf},
  note          = {Stanford CS224N Custom Project, Winter 2023 (https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1234/project.html)},
  abstract      = {Although pretrained large language models (LLMs) can generate convincing natural language about games like chess, they lack positional and contextual knowledge and as such are poor game-playing agents. In this project, I utilize language pretaining; instruction fine-tuning, an additional training regimen with chess-specific tasks presented in natural language; and chain-of-thought prompting, a natural language description of problem reasoning prepended to the answer of a problem, to improve the performance of LLMs at chess move generation (validity/legality and quality of moves). I show that fine-tuned GPT-2-XL, a 1.5B parameter LLM, performs favorably well at move generation compared to ChatGPT with few-shot learning; I also validate the additional benefits of chain-of-thought prompting compared to plain prompts in ChatGPT while highlighting tradeoffs between the quality of natural language and the quality of chess when more verbose prompts are used in the smaller GPT-2-XL.},
}

@misc{kapla:2025:generalized-multi-linear-models-dimension-reduction-tensor-valued-predictors,
  title         = {Generalized Multi-Linear Models for Sufficient Dimension Reduction on Tensor Valued Predictors},
  author        = {Daniel Kapla and Efstathia Bura},
  year          = {2025},
  url           = {https://arxiv.org/abs/2502.20216},
  eprint        = {2502.20216},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ME},
}

@inproceedings{karn:2024:personalized-recommendation-chess-puzzles,
  title         = {Personalized recommendation of chess puzzles},
  author        = {Karn, Aryan and Biradar, Chinmay Anil and Puranik, Aryan and Kireeti, Attili Krishna and Jayashree, R},
  year          = {2024},
  booktitle     = {Computer Science Engineering: Proceedings of the 1st International Conference on Computing and Intelligent Information Systems (ICCIIS 2024), Bangalore, India, 19-20th April, 2024 Volume 1},
  pages         = {29},
  organization  = {CRC Press},
}

@inproceedings{karvonen:2024:dictionary-learning-board-games,
  title         = {Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models},
  author        = {Adam Karvonen and Benjamin Wright and Can Rager and Rico Angell and Jannik Brinkmann and Logan Riggs Smith and Claudio Mayrink Verdun and David Bau and Samuel Marks},
  year          = {2024},
  booktitle     = {ICML 2024 Workshop on Mechanistic Interpretability},
  url           = {https://openreview.net/forum?id=qzsDKwGJyB},
}

@article{karvonen:2024:emergent-world-models-latent-variable-estimation-chess-playing,
  title         = {Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models},
  author        = {Adam Karvonen},
  year          = {2024},
  journal       = {CoRR},
  volume        = {abs/2403.15498},
  doi           = {10.48550/ARXIV.2403.15498},
  url           = {https://doi.org/10.48550/arXiv.2403.15498},
  eprinttype    = {arXiv},
  eprint        = {2403.15498},
}

@thesis{keusch:2025:binary-matching-android-ios-apps,
  title         = {Binary Matching of Android and iOS Apps},
  author        = {Keusch, Alexander},
  year          = {2025},
  doi           = {https://doi.org/10.34726/hss.2025.128603},
  url           = {http://hdl.handle.net/20.500.12708/217584},
  school        = {Technische Universit\"{a}t Wien},
  supervisor    = {Lindorfer, Martina and Bleier, Jakob},
  type          = {Diploma Thesis},
  keyword       = {Mobile Security; Android; iOS; Binary Analysis; Cross-Platform Analysis},
  abstract      = {Android and iOS are the two dominant mobile operating systems in the rapidly expanding smartphone market, serving billions of users worldwide. Both platforms feature extensive app stores with millions of applications available for download. While security measures are in place to prevent the distribution of malicious or vulnerable apps, instances of malware have still been discovered in both stores. These incidents highlight a significant security risk that threatens user privacy and highlights the urgent need for advanced research in detecting malicious code and security vulnerabilities in mobile applications. As a step toward addressing this challenge, this thesis explores the feasibility of using binary similarity detection techniques to identify similarities between Android and iOS applications. To achieve this, we designed and implemented a novel analysis pipeline specifically tailored for comparing Android apps (compiled into binary OAT files) with iOS binaries. This pipeline enables the automatic identification of matches between corresponding applications across both platforms. The pipeline comprises several key stages, including preparing the apps and their third-party libraries for binary analysis, disassembling the binaries using both IDA Pro and Ghidra to account for potential variations introduced by different disassemblers, and conducting similarity analysis on the disassembly results. To assess the effectiveness of our pipeline, we conducted a comprehensive analysis on a dataset of 100 cross-platform apps. Our findings indicate that current binary similarity analysis methods have limitations in directly identifying cross-platform similarities between applications. However, we demonstrated that incorporating third-party libraries into the analysis significantly enhances similarity detection and can help to provide meaningful insights. This highlights the crucial role that third-party libraries play in cross-platform app analysis. Additionally, we found that the choice of disassembler has a significant impact on analysis results. Notably, no single disassembler proved to be clearly superior, as both exhibited their own strengths and limitations. Ultimately, this study offers valuable insights into the challenges and potential of cross-platform binary app analysis using traditional binary diffing techniques, laying a strong foundation for future research in this evolving field.},
}

@online{knopps:collaborative-vs-individual-chess-puzzle-solving,
  title         = {Collaborative versus Individual Chess Puzzle Solving},
  author        = {Knopps, Alex},
  year          = {2025},
  month         = {Feb},
  url           = {https://www.chessable.com/blog/collaborative-versus-individual-chess-puzzle-solving/},
  urldate       = {2025-03-14},
}

@inproceedings{krishnan:2022:automatic-synthesis-interpretable-chess-tactics,
  title         = {Towards the automatic synthesis of interpretable chess tactics},
  author        = {Krishnan, Abhijeet and Martens, Chris},
  year          = {2022},
  month         = {03},
  booktitle     = {Proceedings of the Explainable Agency in Artificial Intelligence Workshop, 36th AAAI Conference on Artificial Intelligence},
  publisher     = {American Association of Artificial Intelligence},
  pages         = {91--97},
}

@inproceedings{krishnan:2022:synthesizing-interpretable-chess-tactics-player-games,
  title         = {Synthesizing interpretable chess tactics from player games},
  author        = {Krishnan, Abhijeet and Martens, Chris},
  year          = {2022},
  month         = {10},
  booktitle     = {Proceedings of the Workshop on Artificial Intelligence for Strategy Games (SG) and Esports Analytics (EA), 18th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  publisher     = {American Association for Artificial Intelligence},
}

@misc{kuboki:2025:policies-multiple-skill-levels-better-strength-estimation-games,
  title         = {Policies of Multiple Skill Levels for Better Strength Estimation in Games},
  author        = {Kyota Kuboki and Tatsuyoshi Ogawa and Chu-Hsuan Hsueh and Shi-Jim Yen and Kokolo Ikeda},
  year          = {2025},
  url           = {https://arxiv.org/abs/2505.00279},
  eprint        = {2505.00279},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}

@inproceedings{kumar:2025:optimizing-ai-driven-chess-bots-strategies-balancing-performance-accuracy-computational-efficiency,
  title         = {Optimizing AI-Driven Chess Bots: Strategies for Balancing Performance, Accuracy, and Computational Efficiency},
  author        = {D, Girish Kumar and Shiva Kumar, K S and Rama Prasad, P Pani and Jalade, Sangamesh C and Praveen Kumar, C T M and D C, Subhashree},
  year          = {2025},
  booktitle     = {2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)},
  pages         = {1--5},
  doi           = {10.1109/ICDCECE65353.2025.11035271},
  keywords      = {Accuracy;Monte Carlo methods;Computational modeling;Decision making;Reinforcement learning;Transformers;Computational efficiency;Artificial intelligence;Optimization;Engines;AI chess engine;reinforcement learning;monte carlo tree search (MCTS);deep learning;transformer-based models;proximal policy optimization (PPO)},
}

@article{kuperwajs:2024:learning-from-rewards-social-information-strategic-behavior,
  title         = {Learning from rewards and social information in naturalistic strategic behavior},
  author        = {Kuperwajs, Ionatan and van Opheusden, Bas and Russek, Evan and Griffiths, Tom},
  year          = {2024},
  month         = {Aug},
  publisher     = {PsyArXiv},
  doi           = {10.31234/osf.io/d8zje},
  url           = {osf.io/preprints/psyarxiv/d8zje},
}

@article{kuperwajs:2025:exploring-resource-rational-planning-time-pressure-online-chess,
  title         = {Exploring resource-rational planning under time pressure in online chess},
  author        = {Kuperwajs, Ionatan and Russek, Evan and Schut, Lisa and Sagiv, Yotam and Mattar, Marcelo G and Ma, Wei Ji and Griffiths, Tom},
  year          = {2025},
  journal       = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume        = {47},
  url           = {https://escholarship.org/uc/item/75b4m9c2},
  abstract      = {Human planning is incredibly efficient. Even in complex situations with many possible courses of action, people are able to make good decisions. Recent proposals suggest that a primary contributor to this efficiency is the intelligent use of cognitive resources, but how people allocate these resources under time constraints is not fully understood. In this work, we conduct a resource-rational analysis of planning in a large data set of online chess games. We first demonstrate that players spent more time thinking when they had more time to do so, and that this effect was especially prevalent when computation was more valuable. Then, we show that additional time spent planning resulted in better selected moves when one existed, and compare between signals of general and immediate time pressure. Finally, we highlight the role of expertise in this setting. Our results provide evidence that people make resource-rational choices when planning under time pressure.},
}
